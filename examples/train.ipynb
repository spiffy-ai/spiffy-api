{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import datetime\n",
    "from IPython.display import display, clear_output\n",
    "import spiffy\n",
    "\n",
    "# Set the API key\n",
    "spiffy.api_key = \"YOUR_API_KEY\"  # get from http://dashboard.spiffy.ai/\n",
    "spiffy.api_key = \"dBTPxGKCel77e0926OLT4dHcQCL3PVBc\"\n",
    "\n",
    "# Training data\n",
    "training_data = [\n",
    "    \"I love Spiffy!\",\n",
    "    \"Spiffy makes personalized language\\nmodels easy to build and deploy.\",\n",
    "    \"Personalized language models will power the future of AI.\",\n",
    "    \"Spiffy trains a specialized LLM for each user.\",\n",
    "    \"Spiffy's approach for personalization is more accurate and cheaper than retreival + prompting.\",\n",
    "    \"Spiffy's efficient inference is ~100x faster than GPT4 + pinecone.\",\n",
    "    \"Spiffy is a leading startup in the space of personalized LLMs.\",\n",
    "]\n",
    "\n",
    "# Specify the model_id\n",
    "model_id = \"api-example-model129\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-13 10:00:42.565708   model_id: clhto9ry60000s601m2n6kr0r\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model_id = await spiffy.acreate_model(model_id=model_id)\n",
    "print(f'{datetime.now()}   model_id: {model_id}')\n",
    "\n",
    "# Upload training data\n",
    "data_id = await spiffy.aupload_training_data(model_id, training_data)\n",
    "print(f'{datetime.now()}   data_id: {data_id}')\n",
    "\n",
    "# Train a model\n",
    "train_id = await spiffy.atrain(model_id)\n",
    "print(f'{datetime.now()}   train_id: {train_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training status\n",
    "status = await spiffy.aget_train_status(train_id)\n",
    "print(f'{datetime.now()}   Training status: {status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Request failed with status code: 404 - {\"requestId\":\"1694624469859221957-YXdzLXVzLWVhc3QtMQ==-a90887f209964e94bef0e40a87fa2fda578596801c84499abf239a1f482ff32e\",\"message\":\"No data product found. Please contact your data provider\"}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Check deployment status\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m available_models \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m spiffy\u001b[39m.\u001b[39maget_available_user_models(model_id)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m}\u001b[39;00m\u001b[39m   Models \u001b[39m\u001b[39m{\u001b[39;00mavailable_models\u001b[39m}\u001b[39;00m\u001b[39m are available for model_id: \u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/spiffy-api/spiffy/api.py:306\u001b[0m, in \u001b[0;36maget_available_user_models\u001b[0;34m(user_id)\u001b[0m\n\u001b[1;32m    302\u001b[0m model_v \u001b[39m=\u001b[39m response\n\u001b[1;32m    303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     \u001b[39m# The `model_available` endpoint returns the default model even if the user doesn't have a personalized model\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     \u001b[39m# so we need to check if the model exists by trying to generate a token from the websocket\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[39mawait\u001b[39;00m _websocket_caller(user_id, model_v, prompt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    307\u001b[0m                             generation_config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_decode_length\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m},\n\u001b[1;32m    308\u001b[0m                             fallback_to_default_model\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39m\u001b[39m__anext__\u001b[39m()\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/spiffy-api/spiffy/api.py:256\u001b[0m, in \u001b[0;36m_websocket_caller\u001b[0;34m(model, model_v, prompt, generation_config, fallback_to_default_model)\u001b[0m\n\u001b[1;32m    253\u001b[0m websocket_url \u001b[39m=\u001b[39m spiffy\u001b[39m.\u001b[39mapi_base_infer\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mws\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    254\u001b[0m websocket_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mwebsocket_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mmodel_v\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 256\u001b[0m token \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m _aget_inference_token(model)\n\u001b[1;32m    257\u001b[0m auth_message \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39maction\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mauth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39midToken\u001b[39m\u001b[39m'\u001b[39m: token}\n\u001b[1;32m    259\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m websockets\u001b[39m.\u001b[39mconnect(websocket_url, open_timeout\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, ping_interval\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, ping_timeout\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m) \u001b[39mas\u001b[39;00m client:\n",
      "File \u001b[0;32m~/spiffy-api/spiffy/api.py:99\u001b[0m, in \u001b[0;36m_aget_inference_token\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mCreates a new token used to authenticate with the inference service.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39margs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m    RuntimeError: For all errors.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mspiffy\u001b[39m.\u001b[39mapi_base_train\u001b[39m}\u001b[39;00m\u001b[39m/auth/token\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 99\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m _api_requester(url, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m\"\u001b[39m: model})\n\u001b[1;32m    100\u001b[0m response \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response)\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m response:\n",
      "File \u001b[0;32m~/spiffy-api/spiffy/api.py:50\u001b[0m, in \u001b[0;36m_api_requester\u001b[0;34m(api_url, method, data, stream)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m             response_text \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m response\u001b[39m.\u001b[39mtext()\n\u001b[0;32m---> 50\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequest failed with status code: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mresponse_text\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThis should never happen\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Request failed with status code: 404 - {\"requestId\":\"1694624469859221957-YXdzLXVzLWVhc3QtMQ==-a90887f209964e94bef0e40a87fa2fda578596801c84499abf239a1f482ff32e\",\"message\":\"No data product found. Please contact your data provider\"}\n"
     ]
    }
   ],
   "source": [
    "# Check deployment status\n",
    "available_models = await spiffy.aget_available_user_models(model_id)\n",
    "print(f'{datetime.now()}   Models {available_models} are available for model_id: {model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiffy's efficient inference is\n",
      "-\n",
      "b'data: {\"type\":\"status\",\"message\":\"Loading /mnt/deployed##clhto9ry60000s601m2n6kr0r.\"}\\n\\ndata: {\"type\":\"status\",\"message\":\"Finished loading /mnt/deployed##clhto9ry60000s601m2n6kr0r.\"}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\"\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" based\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" on\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" a\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" novel\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" approach\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" that\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" uses\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" a\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" combination\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" of\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" symbol\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\"ic\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" manip\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\"ulation\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" and\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" neural\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" networks\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\".\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\" [\",\"\",\"\"]}\\n\\ndata: {\"type\":\"token_update\",\"tokens\":[\"S\",\"\",\"\"]}\\n\\ndata: {\"type\":\"generation_complete\"}\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "# Generate\n",
    "prompt = \"Spiffy's efficient inference is\"\n",
    "generated = prompt\n",
    "print(prompt)\n",
    "async for output in spiffy.agenerate(model_id, 'v2', prompt=prompt, generation_config={}):\n",
    "    # generated += output[0]\n",
    "    print('-')\n",
    "    print(output)\n",
    "    # clear_output(wait=True)\n",
    "    # display(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
